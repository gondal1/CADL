{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import libs.batch_norm as bn\n",
    "from libs.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from libs.datasets import CELEB\n",
    "files = CELEB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Inpput pipeline\n",
    "from libs.dataset_utils import create_input_pipeline\n",
    "batch_size = 100\n",
    "n_epochs = 10\n",
    "input_shape = [218, 178, 3]\n",
    "crop_shape = [64, 64, 3]\n",
    "crop_factor = 0.8\n",
    "batch = create_input_pipeline(\n",
    "    files=files,\n",
    "    batch_size=batch_size,\n",
    "    n_epochs=n_epochs,\n",
    "    crop_shape=crop_shape,\n",
    "    crop_factor=crop_factor,\n",
    "    shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess=sess, coord=coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 64, 64, 3)\n",
      "(dtype('float32'), dtype('float32'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7efee9260a50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQxvCNr7B0IawjW8wtCH+D9cZcvI4iML/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efee7cae090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_xs = sess.run(batch)\n",
    "# We get batch_size at a time, so 100\n",
    "print(batch_xs.shape)\n",
    "# The datatype is float32 since what is what we use in the tensorflow graph\n",
    "# And the max value still has the original image range from 0-255\n",
    "print(batch_xs.dtype, np.max(batch_xs.dtype))\n",
    "# So to plot it, we'll need to divide by 255.\n",
    "plt.imshow(batch_xs[0] / 255.0)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def encoder(x, phase_train, dimensions=[], filter_sizes=[],\n",
    "            convolutional=False, activation=tf.nn.relu,\n",
    "            output_activation=tf.nn.sigmoid, reuse=False):\n",
    "    \"\"\"Encoder network codes input `x` to layers defined by dimensions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : tf.Tensor\n",
    "        Input to the encoder network, e.g. tf.Placeholder or tf.Variable\n",
    "    phase_train : tf.Placeholder\n",
    "        Placeholder defining whether the network is in train mode or not.\n",
    "        Used for changing the behavior of batch normalization which updates\n",
    "        its statistics during train mode.\n",
    "    dimensions : list, optional\n",
    "        List of the number of neurons in each layer (convolutional=False) -or-\n",
    "        List of the number of filters in each layer (convolutional=True), e.g.\n",
    "        [100, 100, 100, 100] for a 4-layer deep network with 100 in each layer.\n",
    "    filter_sizes : list, optional\n",
    "        List of the size of the kernel in each layer, e.g.:\n",
    "        [3, 3, 3, 3] is a 4-layer deep network w/ 3 x 3 kernels in every layer.\n",
    "    convolutional : bool, optional\n",
    "        Whether or not to use convolutional layers.\n",
    "    activation : fn, optional\n",
    "        Function for applying an activation, e.g. tf.nn.relu\n",
    "    output_activation : fn, optional\n",
    "        Function for applying an activation on the last layer, e.g. tf.nn.relu\n",
    "    reuse : bool, optional\n",
    "        For each layer's variable scope, whether to reuse existing variables.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    h : tf.Tensor\n",
    "        Output tensor of the encoder\n",
    "    \"\"\"\n",
    "    # %%\n",
    "    # ensure 2-d is converted to square tensor.\n",
    "    if convolutional:\n",
    "        x_tensor = to_tensor(x)\n",
    "    else:\n",
    "        x_tensor = tf.reshape(\n",
    "            tensor=x,\n",
    "            shape=[-1, dimensions[0]])\n",
    "        dimensions = dimensions[1:]\n",
    "    current_input = x_tensor\n",
    "\n",
    "    for layer_i, n_output in enumerate(dimensions):\n",
    "        with tf.variable_scope(str(layer_i), reuse=reuse):\n",
    "            if convolutional:\n",
    "                h, W = conv2d(\n",
    "                    x=current_input,\n",
    "                    n_output=n_output,\n",
    "                    k_h=filter_sizes[layer_i],\n",
    "                    k_w=filter_sizes[layer_i],\n",
    "                    padding='SAME',\n",
    "                    reuse=reuse)\n",
    "            else:\n",
    "                h, W = linear(\n",
    "                    x=current_input,\n",
    "                    n_output=n_output,\n",
    "                    reuse=reuse)\n",
    "            norm = bn.batch_norm(\n",
    "                x=h,\n",
    "                phase_train=phase_train,\n",
    "                name='bn',\n",
    "                reuse=reuse)\n",
    "            output = activation(norm)\n",
    "\n",
    "        current_input = output\n",
    "\n",
    "    flattened = flatten(current_input, name='flatten', reuse=reuse)\n",
    "\n",
    "    if output_activation is None:\n",
    "        return flattened\n",
    "    else:\n",
    "        return output_activation(flattened)\n",
    "\n",
    "\n",
    "def decoder(z,\n",
    "            phase_train,\n",
    "            dimensions=[],\n",
    "            channels=[],\n",
    "            filter_sizes=[],\n",
    "            convolutional=False,\n",
    "            activation=tf.nn.relu,\n",
    "            output_activation=tf.nn.tanh,\n",
    "            reuse=None):\n",
    "    \"\"\"Decoder network codes input `x` to layers defined by dimensions.\n",
    "\n",
    "    In contrast with `encoder`, this requires information on the number of\n",
    "    output channels in each layer for convolution.  Otherwise, it is mostly\n",
    "    the same.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    z : tf.Tensor\n",
    "        Input to the decoder network, e.g. tf.Placeholder or tf.Variable\n",
    "    phase_train : tf.Placeholder\n",
    "        Placeholder defining whether the network is in train mode or not.\n",
    "        Used for changing the behavior of batch normalization which updates\n",
    "        its statistics during train mode.\n",
    "    dimensions : list, optional\n",
    "        List of the number of neurons in each layer (convolutional=False) -or-\n",
    "        List of the number of filters in each layer (convolutional=True), e.g.\n",
    "        [100, 100, 100, 100] for a 4-layer deep network with 100 in each layer.\n",
    "    channels : list, optional\n",
    "        For decoding when convolutional=True, require the number of output\n",
    "        channels in each layer.\n",
    "    filter_sizes : list, optional\n",
    "        List of the size of the kernel in each layer, e.g.:\n",
    "        [3, 3, 3, 3] is a 4-layer deep network w/ 3 x 3 kernels in every layer.\n",
    "    convolutional : bool, optional\n",
    "        Whether or not to use convolutional layers.\n",
    "    activation : fn, optional\n",
    "        Function for applying an activation, e.g. tf.nn.relu\n",
    "    output_activation : fn, optional\n",
    "        Function for applying an activation on the last layer, e.g. tf.nn.relu\n",
    "    reuse : bool, optional\n",
    "        For each layer's variable scope, whether to reuse existing variables.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    h : tf.Tensor\n",
    "        Output tensor of the decoder\n",
    "    \"\"\"\n",
    "\n",
    "    if convolutional:\n",
    "        with tf.variable_scope('fc', reuse=reuse):\n",
    "            z1, W = linear(\n",
    "                x=z,\n",
    "                n_output=channels[0] * dimensions[0][0] * dimensions[0][1],\n",
    "                reuse=reuse)\n",
    "            rsz = tf.reshape(\n",
    "                z1, [-1, dimensions[0][0], dimensions[0][1], channels[0]])\n",
    "            current_input = activation(\n",
    "                features=bn.batch_norm(\n",
    "                    name='bn',\n",
    "                    x=rsz,\n",
    "                    phase_train=phase_train,\n",
    "                    reuse=reuse))\n",
    "\n",
    "        dimensions = dimensions[1:]\n",
    "        channels = channels[1:]\n",
    "        filter_sizes = filter_sizes[1:]\n",
    "    else:\n",
    "        current_input = z\n",
    "\n",
    "    for layer_i, n_output in enumerate(dimensions):\n",
    "        with tf.variable_scope(str(layer_i), reuse=reuse):\n",
    "\n",
    "            if convolutional:\n",
    "                h, W = deconv2d(\n",
    "                    x=current_input,\n",
    "                    n_output_h=n_output[0],\n",
    "                    n_output_w=n_output[1],\n",
    "                    n_output_ch=channels[layer_i],\n",
    "                    k_h=filter_sizes[layer_i],\n",
    "                    k_w=filter_sizes[layer_i],\n",
    "                    padding='SAME',\n",
    "                    reuse=reuse)\n",
    "            else:\n",
    "                h, W = linear(\n",
    "                    x=current_input,\n",
    "                    n_output=n_output,\n",
    "                    reuse=reuse)\n",
    "\n",
    "            if layer_i < len(dimensions) - 1:\n",
    "                norm = bn.batch_norm(\n",
    "                    x=h,\n",
    "                    phase_train=phase_train,\n",
    "                    name='bn', reuse=reuse)\n",
    "                output = activation(norm)\n",
    "            else:\n",
    "                output = h\n",
    "        current_input = output\n",
    "\n",
    "    if output_activation is None:\n",
    "        return current_input\n",
    "    else:\n",
    "        return output_activation(current_input)\n",
    "\n",
    "\n",
    "def generator(z, phase_train, output_h, output_w, convolutional=True,\n",
    "              n_features=32, rgb=False, reuse=None):\n",
    "    \"\"\"Simple interface to build a decoder network given the input parameters.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    z : tf.Tensor\n",
    "        Input to the generator, i.e. tf.Placeholder of tf.Variable\n",
    "    phase_train : tf.Placeholder of type bool\n",
    "        Whether or not the network should be trained (used for Batch Norm).\n",
    "    output_h : int\n",
    "        Final generated height\n",
    "    output_w : int\n",
    "        Final generated width\n",
    "    convolutional : bool, optional\n",
    "        Whether or not to build a convolutional generative network.\n",
    "    n_features : int, optional\n",
    "        Number of channels to use in the last hidden layer.\n",
    "    rgb : bool, optional\n",
    "        Whether or not the final generated image is RGB or not.\n",
    "    reuse : None, optional\n",
    "        Whether or not to reuse the variables if they are already created.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    x_tilde : tf.Tensor\n",
    "        Output of the generator network.\n",
    "    \"\"\"\n",
    "    n_channels = 3 if rgb else 1\n",
    "    with tf.variable_scope('generator', reuse=reuse):\n",
    "        return decoder(z=z,\n",
    "                       phase_train=phase_train,\n",
    "                       convolutional=convolutional,\n",
    "                       filter_sizes=[5, 5, 5, 5, 5],\n",
    "                       channels=[n_features * 8, n_features * 4,\n",
    "                                 n_features * 2, n_features, n_channels],\n",
    "                       dimensions=[\n",
    "                           [output_h // 16, output_w // 16],\n",
    "                           [output_h // 8, output_w // 8],\n",
    "                           [output_h // 4, output_w // 4],\n",
    "                           [output_h // 2, output_w // 2],\n",
    "                           [output_h, output_w]]\n",
    "                       if convolutional else [384, 512, n_features],\n",
    "                       activation=tf.nn.relu6,\n",
    "                       output_activation=tf.nn.tanh,\n",
    "                       reuse=reuse)\n",
    "\n",
    "\n",
    "def discriminator(x, phase_train, convolutional=True,\n",
    "                  n_features=32, rgb=False, reuse=False):\n",
    "    \"\"\"Summary\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : TYPE\n",
    "        Description\n",
    "    phase_train : TYPE\n",
    "        Description\n",
    "    convolutional : bool, optional\n",
    "        Description\n",
    "    n_features : int, optional\n",
    "        Description\n",
    "    rgb : bool, optional\n",
    "        Description\n",
    "    reuse : bool, optional\n",
    "        Description\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    name : TYPE\n",
    "        Description\n",
    "    \"\"\"\n",
    "    n_channels = 3 if rgb else 1\n",
    "    with tf.variable_scope('discriminator', reuse=reuse):\n",
    "        return encoder(x=x,\n",
    "                       phase_train=phase_train,\n",
    "                       convolutional=convolutional,\n",
    "                       filter_sizes=[5, 5, 5, 5],\n",
    "                       dimensions=[n_features, n_features * 2,\n",
    "                                   n_features * 4, n_features * 8]\n",
    "                       if convolutional\n",
    "                       else [n_features, 128, 256],\n",
    "                       activation=tf.nn.relu6,\n",
    "                       output_activation=None,\n",
    "                       reuse=reuse)\n",
    "\n",
    "\n",
    "def GAN(input_shape, n_latent, n_features, rgb, debug=True):\n",
    "    \"\"\"Summary\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_shape : TYPE\n",
    "        Description\n",
    "    n_latent : TYPE\n",
    "        Description\n",
    "    n_features : TYPE\n",
    "        Description\n",
    "    rgb : TYPE\n",
    "        Description\n",
    "    debug : bool, optional\n",
    "        Description\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    name : TYPE\n",
    "        Description\n",
    "    \"\"\"\n",
    "    # Real input samples\n",
    "    # n_features is either the image dimension or flattened number of features\n",
    "    x = tf.placeholder(tf.float32, input_shape, 'x')\n",
    "    x = (x / 127.5) - 1.0\n",
    "    #sum_x = tf.image_summary(\"x\", x)\n",
    "    phase_train = tf.placeholder(tf.bool, name='phase_train')\n",
    "\n",
    "    # Discriminator for real input samples\n",
    "    D_real_logits = discriminator(\n",
    "        x, phase_train, n_features=n_features, rgb=rgb)\n",
    "    D_real = tf.nn.sigmoid(D_real_logits)\n",
    "    #sum_D_real = tf.histogram_summary(\"D_real\", D_real)\n",
    "\n",
    "    # Generator tries to recreate input samples using latent feature vector\n",
    "    z = tf.placeholder(tf.float32, [None, n_latent], 'z')\n",
    "    #sum_z = tf.histogram_summary(\"z\", z)\n",
    "    G = generator(\n",
    "        z, phase_train,\n",
    "        output_h=input_shape[1], output_w=input_shape[2],\n",
    "        n_features=n_features, rgb=rgb)\n",
    "    #sum_G = tf.image_summary(\"G\", G)\n",
    "\n",
    "    # Discriminator for generated samples\n",
    "    D_fake_logits = discriminator(\n",
    "        G, phase_train, n_features=n_features, rgb=rgb, reuse=True)\n",
    "    D_fake = tf.nn.sigmoid(D_fake_logits)\n",
    "    #sum_D_fake = tf.histogram_summary(\"D_fake\", D_fake)\n",
    "\n",
    "    with tf.variable_scope('loss'):\n",
    "        # Loss functions\n",
    "        loss_D_real = binary_cross_entropy(\n",
    "            D_real, tf.ones_like(D_real), name='loss_D_real')\n",
    "        loss_D_fake = binary_cross_entropy(\n",
    "            D_fake, tf.zeros_like(D_fake), name='loss_D_fake')\n",
    "        loss_D = tf.reduce_mean((loss_D_real + loss_D_fake) / 2)\n",
    "        loss_G = tf.reduce_mean(binary_cross_entropy(\n",
    "            D_fake, tf.ones_like(D_fake), name='loss_G'))\n",
    "        '''\n",
    "        # Summaries\n",
    "        sum_loss_D_real = tf.histogram_summary(\"loss_D_real\", loss_D_real)\n",
    "        sum_loss_D_fake = tf.histogram_summary(\"loss_D_fake\", loss_D_fake)\n",
    "        sum_loss_D = tf.scalar_summary(\"loss_D\", loss_D)\n",
    "        sum_loss_G = tf.scalar_summary(\"loss_G\", loss_G)\n",
    "        sum_D_real = tf.histogram_summary(\"D_real\", D_real)\n",
    "        sum_D_fake = tf.histogram_summary(\"D_fake\", D_fake)\n",
    "        '''\n",
    "\n",
    "\n",
    "    return {\n",
    "        'loss_D': loss_D,\n",
    "        'loss_G': loss_G,\n",
    "        'x': x,\n",
    "        'G': G,\n",
    "        'z': z,\n",
    "        'train': phase_train}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init_lr_g = 1e-4\n",
    "init_lr_d = 1e-4\n",
    "n_latent = 100\n",
    "n_epochs = 1000000\n",
    "batch_size = 200\n",
    "n_samples = 15\n",
    "input_shape = [218, 178, 3]\n",
    "crop_shape = [64, 64, 3]\n",
    "crop_factor = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gan = GAN(input_shape=[None] + crop_shape, n_features=10, n_latent=n_latent, rgb=True, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training discriminator variables:\n",
      "[u'discriminator/0/conv2d/W:0', u'discriminator/0/conv2d/b:0', u'discriminator/0/bn/beta:0', u'discriminator/0/bn/gamma:0', u'discriminator/1/conv2d/W:0', u'discriminator/1/conv2d/b:0', u'discriminator/1/bn/beta:0', u'discriminator/1/bn/gamma:0', u'discriminator/2/conv2d/W:0', u'discriminator/2/conv2d/b:0', u'discriminator/2/bn/beta:0', u'discriminator/2/bn/gamma:0', u'discriminator/3/conv2d/W:0', u'discriminator/3/conv2d/b:0', u'discriminator/3/bn/beta:0', u'discriminator/3/bn/gamma:0']\n"
     ]
    }
   ],
   "source": [
    "vari_d, vari_g = [], []\n",
    "vars_d = [v for v in tf.trainable_variables() if v.name.startswith('discriminator')] \n",
    "print('Training discriminator variables:')\n",
    "[vari_d.append((v.name)) for v in tf.trainable_variables() if v.name.startswith('discriminator')]\n",
    "print vari_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training generator variables:\n",
      "[u'generator/fc/fc/W:0', u'generator/fc/fc/b:0', u'generator/fc/bn/beta:0', u'generator/fc/bn/gamma:0', u'generator/0/deconv2d/W:0', u'generator/0/deconv2d/b:0', u'generator/0/bn/beta:0', u'generator/0/bn/gamma:0', u'generator/1/deconv2d/W:0', u'generator/1/deconv2d/b:0', u'generator/1/bn/beta:0', u'generator/1/bn/gamma:0', u'generator/2/deconv2d/W:0', u'generator/2/deconv2d/b:0', u'generator/2/bn/beta:0', u'generator/2/bn/gamma:0', u'generator/3/deconv2d/W:0', u'generator/3/deconv2d/b:0']\n"
     ]
    }
   ],
   "source": [
    "vars_g = [v for v in tf.trainable_variables() if v.name.startswith('generator')]\n",
    "print('Training generator variables:')\n",
    "[vari_g.append(v.name) for v in tf.trainable_variables() if v.name.startswith('generator')]\n",
    "print vari_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zs = np.random.uniform(\n",
    "        -1.0, 1.0, [4, n_latent]).astype(np.float32)\n",
    "zs = make_latent_manifold(zs, n_samples)\n",
    "\n",
    "lr_g = tf.placeholder(tf.float32, shape=[], name='learning_rate_g')\n",
    "lr_d = tf.placeholder(tf.float32, shape=[], name='learning_rate_d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from tf.contrib.layers import apply_regularization\n",
    "    d_reg = apply_regularization(tf.contrib.layers.l2_regularizer(1e-6), vars_d)\n",
    "    g_reg = apply_regularization(tf.contrib.layers.l2_regularizer(1e-6), vars_g)\n",
    "except:\n",
    "    d_reg, g_reg = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opt_g = tf.train.AdamOptimizer(lr_g, name='Adam_g').minimize(gan['loss_G'], var_list=vars_g) #gan['loss_G'] + g_reg\n",
    "opt_d = tf.train.AdamOptimizer(lr_d, name='Adam_d').minimize(gan['loss_D'], var_list=vars_d)\n",
    "\n",
    "# %%\n",
    "# We create a session to use the graph\n",
    "sess = tf.Session()\n",
    "init_op = tf.initialize_all_variables()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "#sums = gan['sums']\n",
    "#G_sum_op = tf.merge_summary([sums['G'], sums['loss_G'], sums['z'], sums['loss_D_fake'], sums['D_fake']])\n",
    "#D_sum_op = tf.merge_summary([sums['loss_D'], sums['loss_D_real'], sums['loss_D_fake'],\n",
    "#        sums['z'], sums['x'], sums['D_real'], sums['D_fake']])\n",
    "#writer = tf.train.SummaryWriter(\"./logs\", sess.graph_def)\n",
    "\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "sess.run(init_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if os.path.exists(\"gan.ckpt\"):\n",
    "    saver.restore(sess, \"gan.ckpt\")\n",
    "    print(\"GAN model restored.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "step_i, t_i = 0, 0\n",
    "loss_d = 1\n",
    "loss_g = 1\n",
    "n_loss_d, total_loss_d = 1, 1\n",
    "n_loss_g, total_loss_g = 1, 1\n",
    "try:\n",
    "    while not coord.should_stop():\n",
    "        batch_xs = sess.run(batch)\n",
    "        step_i += 1\n",
    "        batch_zs = np.random.uniform(-1.0, 1.0, [batch_size, n_latent]).astype(np.float32)\n",
    "        \n",
    "        print '1st step', np.shape(batch_zs)\n",
    "        \n",
    "\n",
    "        this_lr_g = min(1e-2, max(1e-6, init_lr_g * (loss_g / loss_d)**2))\n",
    "        this_lr_d = min(1e-2, max(1e-6, init_lr_d * (loss_d / loss_g)**2))\n",
    "        \n",
    "        print 'lr_g', this_lr_g\n",
    "        print 'lr_d', this_lr_d\n",
    "        # this_lr_d *= ((1.0 - (step_i / 100000)) ** 2)\n",
    "        # this_lr_g *= ((1.0 - (step_i / 100000)) ** 2)\n",
    "\n",
    "        # if np.random.random() > (loss_g / (loss_d + loss_g)):\n",
    "        #if step_i % 3 == 1:\n",
    "        loss_d, _ = sess.run([gan['loss_D'], opt_d],\n",
    "                                        feed_dict={gan['x']: batch_xs,\n",
    "                                                   gan['z']: batch_zs,\n",
    "                                                   gan['train']: True,\n",
    "                                                   lr_d: this_lr_d})\n",
    "        total_loss_d += loss_d\n",
    "        n_loss_d += 1\n",
    "            #writer.add_summary(sum_d, step_i)\n",
    "        print('%04d d* = lr: %0.08f, loss: %08.06f, \\t' %\n",
    "                      (step_i, this_lr_d, loss_d) +\n",
    "                      'g  = lr: %0.08f, loss: %08.06f' % (this_lr_g, loss_g))\n",
    "        #else:\n",
    "        loss_g, _ = sess.run([gan['loss_G'], opt_g],\n",
    "                                        feed_dict={gan['z']: batch_zs,\n",
    "                                                    gan['train']: True,\n",
    "                                                    lr_g: this_lr_g})\n",
    "        total_loss_g += loss_g\n",
    "        n_loss_g += 1\n",
    "            #writer.add_summary(sum_g, step_i)\n",
    "        print('%04d d  = lr: %0.08f, loss: %08.06f, \\t' %\n",
    "                      (step_i, this_lr_d, loss_d) +\n",
    "                      'g* = lr: %0.08f, loss: %08.06f' % (this_lr_g, loss_g))\n",
    "\n",
    "        if step_i % 100 == 0:\n",
    "            samples = sess.run(gan['G'], feed_dict={\n",
    "                gan['z']: zs,\n",
    "                gan['train']: False})\n",
    "            montage(np.clip((samples + 1) * 127.5, 0, 255).astype(np.uint8), 'imgs/gan_%08d.png' % t_i)\n",
    "            t_i += 1\n",
    "\n",
    "            print('generator loss:', total_loss_g / n_loss_g)\n",
    "            print('discriminator loss:', total_loss_d / n_loss_d)\n",
    "\n",
    "            # Save the variables to disk.\n",
    "            save_path = saver.save(sess, \"./gan.ckpt\",\n",
    "                                   global_step=step_i,\n",
    "                                   write_meta_graph=False)\n",
    "            print(\"Model saved in file: %s\" % save_path)\n",
    "except tf.errors.OutOfRangeError:\n",
    "    print('Done training -- epoch limit reached')\n",
    "finally:\n",
    "    # One of the threads has issued an exception.  So let's tell all the\n",
    "    # threads to shutdown.\n",
    "    coord.request_stop()\n",
    "\n",
    "# Wait until all threads have finished.\n",
    "coord.join(threads)\n",
    "\n",
    "# Clean up the session.\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
